\chapter{Literature Review}\label{C:lit}

The analysis of complex time series has long relied on both time-domain and frequency-domain techniques. 
However, traditional methods often fall short in capturing nonlinear dynamics or are limited by strict assumptions such as stationarity and Gaussianity. 
The ordinal symbolic approach introduced by Bandt and Pompe in 2002 marked a significant theoretical advance by enabling robust, model-free characterization of time series. 
Their approach, rooted in information theory, involves converting segments of time series data into symbols based on the ordinal (rank) relationships among the data points.
These symbols are called ``ordinal patterns.''
%%% ACF We need the histogram here
%%% ACF 
The scaled Shannon entropy calculated from the distribution of these patterns, now widely known as permutation entropy, has become a central tool in nonlinear data analysis. 
%%% 
%%% ACF We need the statistical complexity here
This literature review discusses the theoretical foundations and applications of the Bandt-Pompe methodology, as well as recent developments and challenges outlined in contemporary works, including the reviews by Amigó et al.~\cite{amigo2023ordinal} and Leyva et al.~\cite{Leyva2022}.

%Waschke et al.~\cite{Waschke2025} investigated how the hippocampus encodes sensory information during memory formation by analyzing time series data from single-neuron recordings in 34 human patients undergoing neurosurgical procedures. Using permutation entropy, a measure of temporal complexity, they quantified trial-to-trial variability in neuronal spiking activity during a visual memory task. Their analysis revealed that hippocampal neurons dynamically track the richness of visual input, with greater spiking variability corresponding to more complex or information-rich stimuli. Key features of the study include the use of intracranial single-neuron recordings in humans, the application of entropy-based metrics to capture neural variability, and the discovery that this variability not only reflects stimulus content but also predicts subsequent memory performance, highlighting the role of variability as a functional marker of memory encoding. 

%Another study by Alessio Perinelli and Leonardo Ricci~\cite{Perinelli2025} aimed to develop a statistically grounded method to evaluate the temporal stationarity of resting-state EEG data using permutation entropy (PE). Researchers analyzed EEG recordings from the LEMON dataset, involving young and elderly adults, during alternating eyes-open (EO) and eyes-closed (EC) conditions. EEG signals were source-reconstructed into 30 brain regions, segmented, and assessed for entropy-based stability using a chi-square test on PE values. Key findings revealed greater nonstationarity in elderly participants and in EC conditions, with unstable segments showing higher PE, indicating increased signal complexity. This method provides a reliable framework for identifying unstable EEG periods and has potential applications in clinical diagnostics and real-time neural monitoring.

%Li et al.~\cite{Li2025} discussed the Multiscale Grayscale Dispersion Entropy (MGDE) model, an advanced entropy-based metric designed to assess the complexity of time series data across multiple temporal scales. Building upon the foundation of Grayscale Dispersion Entropy (GDE), MGDE incorporates a multiscale framework that enables a more comprehensive analysis of dynamic behaviors in time series. The methodology involves applying a coarse-graining process to the original time series data, followed by the computation of GDE at each scale, effectively capturing the signal's complexity at various temporal resolutions. Key findings from the study demonstrate that MGDE effectively distinguishes between different types of signals, including white Gaussian noise, $1/f$ noise, and chaotic signals, highlighting its robustness and sensitivity to underlying dynamics. The research also emphasizes MGDE's computational efficiency and its potential applicability in real-time signal processing. Looking ahead, MGDE holds significant promise for diverse applications in fields such as biomedical engineering, finance, and environmental science, where understanding the multiscale complexity of time series data is essential.

%The article titled "Detection of Ship Echo Signals in Reverberation Background Based on Sample Entropy and Multiscale Sample Entropy" by Li et al.~\cite{Li2025a}, addresses the challenge of detecting ship echo signals amidst reverberation in underwater environments. Traditional frequency-based detection methods often struggle under conditions of low signal-to-reverberation ratios (SRR) and minimal Doppler shifts. To overcome these limitations, the authors introduce entropy-based approaches, specifically, Sample Entropy (SampEn) and Multiscale Sample Entropy (MSE), to analyze the complexity differences between target echoes and reverberation noise. Through simulations under various SRR and Doppler shift scenarios, the study demonstrates that while frequency-based methods falter in challenging conditions, SampEn and MSE effectively detect target echoes. Notably, MSE maintains detection capabilities even when the Doppler shift is negligible and the SRR drops to 0 dB. These findings highlight the robustness of entropy-based methods in complex underwater acoustic environments, suggesting their potential for enhancing real-time sonar systems and underwater surveillance applications.

%Mao et al.~\cite{Mao2025} introduces an innovative approach for detecting short-wave defects in railway tracks by analyzing axle box acceleration signals. The authors propose a new metric called Dispersion Transition Entropy (DTE), which quantifies the dynamic complexity of time series data by examining transitions between dispersion patterns. To enhance the sensitivity of this measure, they integrate the Jensen–Fisher Divergence (JFD), a statistical tool adept at highlighting local differences in probability distributions. By computing the JFD between dispersion-transition distributions of consecutive sliding windows, the method effectively identifies anomalies such as rail corrugation and impact defects. Experimental results demonstrate that this combined approach outperforms traditional methods in distinguishing chaotic signals from stochastic noise, offering a robust solution for real-time rail defect detection and contributing to improved railway maintenance and safety.

%An innovative entropy-based metric designed to quantify synchrony in complex time series data was proposed by Lin A. and Lin G.~\cite{Lin2025}. The method extends traditional diversity entropy by incorporating a multiscale framework, enabling the analysis of signal complexity across various temporal resolutions. By evaluating the diversity of patterns within time series at multiple scales, the approach captures both local and global synchrony features, making it particularly effective for detecting subtle synchronization phenomena in nonlinear and nonstationary signals. The study demonstrates the utility of this metric through applications to both synthetic and real-world datasets, highlighting its robustness and sensitivity in identifying synchrony patterns that may be overlooked by conventional methods. The findings suggest that multiscale modified diversity entropy offers a valuable tool for researchers and practitioners in fields such as neuroscience, physiology, and engineering, where understanding the synchrony of complex systems is crucial.

%A novel approach based on Fuzzy Diversity Entropy (FDE) to enhance the accuracy and sensitivity of fault detection in rotating machinery was introduced by Jiao et al.~\cite{Jiao2025}. This method builds on traditional Diversity Entropy (DE) by addressing its limitations in detecting subtle signal variations caused by rigid classification boundaries. By integrating fuzzy set theory, FDE replaces fixed probability assignments with fuzzy membership degrees, enabling a more nuanced quantification of signal complexity and better preservation of diversity information. This enhancement allows FDE to effectively distinguish between similar cosine similarity values that DE might treat as equivalent, thus increasing sensitivity to minor signal changes. The effectiveness of FDE was validated using both simulated and experimental vibration signals from rotating machinery. Comparative analyses show that FDE outperforms conventional DE, Fuzzy Entropy (FE), and Permutation Entropy (PE) in terms of complexity quantification, parameter sensitivity, and computational efficiency. These results suggest that FDE is a robust and efficient tool for intelligent fault diagnosis, with strong potential for real-time monitoring and predictive maintenance of rotating machinery systems.

%A novel signal processing framework to enhance the sensitivity and accuracy of quartz-enhanced photoacoustic spectroscopy (QEPAS) systems for gas detection was proposed by Zhang et al.~\cite{Zhang2025}. The method combines Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN), Permutation Entropy (PE), and Wavelet Threshold Denoising (WTD) to efficiently extract and denoise key components from complex acoustic signals. By decomposing the signal into intrinsic mode functions (IMFs) with ICEEMDAN, selecting relevant components using PE, and applying WTD to reduce residual noise, the approach significantly boosts the signal-to-noise ratio. Experimental validation shows that this integrated technique outperforms conventional denoising methods, resulting in more accurate gas concentration measurements. The work highlights the potential of advanced entropy-based and multi-stage denoising strategies in improving the performance and reliability of QEPAS systems for applications such as environmental monitoring, industrial safety, and medical diagnostics.

%Wang et al.~\cite{Wang2025} introduces a novel entropy-based approach aimed at enhancing the accuracy of fault detection in rolling bearings. This method, termed Distance Similarity Entropy (DSE), integrates distance metrics with entropy calculations to effectively capture subtle nonlinear characteristics in vibration signals. By quantifying the similarity between signal segments through distance measures and assessing their complexity via entropy, DSE provides a more sensitive feature extraction technique compared to traditional entropy methods. Experimental validations demonstrate that DSE outperforms existing approaches in identifying bearing faults, especially in scenarios with limited or noisy data, highlighting its potential for practical applications in machinery fault diagnosis.

%Fan and Ding~\cite{Fan2025} presents a novel class of three-dimensional discrete memristive chaotic maps (3DDMCM) derived from a discrete cosine memristor model. These maps exhibit unique dynamic behaviors, including the generation of multi-type hidden attractors such as multi-wave, multi-cavity, multi-firework, and multi-diamond patterns, even in the absence of equilibrium points. By adjusting control parameters $\mu$ and $b$, the system can produce various chaotic attractors, demonstrating phenomena akin to multi-scroll patterns. Dynamic analyses reveal that the system possesses two positive Lyapunov exponents, high complexity, offset boosting, and diverse geometric control behaviors. A pseudo-random number generator (PRNG) based on this system was constructed, showcasing desirable statistical properties suitable for secure communication applications. Furthermore, the feasibility of implementing the 3DDMCM was confirmed through deployment on a DSP development board, underscoring its potential for practical engineering applications

\section{Theoretical Foundations of the Bandt-Pompe Methodology}

Bandt and Pompe~\cite{PhysRevLett.88.174102} introduced in 2002 a novel approach to time series analysis by focusing on the ordinal relationships between data points rather than their actual values. 
This method involves mapping a time series into a sequence of symbols representing the relative ordering of values within embedding vectors. 
The authors computed the scaled Shannon entropy (the permutation entropy) of the frequency distribution of these patterns, and used it as a measure of the signal complexity.
Since the symbols are invariant under monotonic transformations and robust to observational noise, so is any feature derived from them.
This approach requires minimal assumptions about the data, it is computationally efficient, and effective for short time series, making it suitable for a wide range of applications~\cite{Zanin2012}.

%The Shannon entropy is employed to quantify the unpredictability or complexity of the symbolic sequence. 
%The resulting permutation entropy has several attractive properties: it is computationally efficient, non-parametric, ~\cite{ Zanin2012}. 
%%% ACF A statistical measure of complexity discussed how C must behave, and the authors proposed a (not so good) way of computing it
%%% ACF {EEG} analysis using wavelet-based information tools proposes the Jensen-Shannon distance, that leads to the statistical complexity as we use it.
A further theoretical development by Rosso et al.~\cite{Rosso2007} extended method by introducing the statistical complexity, which measures both the system's randomness and structure. 
Plotting the permutation entropy against the statistical complexity yields the entropy-complexity plane, a diagnostic tool for classifying different dynamical regimes.

\section{Applications and Advances}

The Bandt-Pompe framework has since found broad applications across domains, as reviewed by Amigó et al.~\cite{amigo2023ordinal}. 
This section is divided into three subsections that analyze the applications of the Bandt and Pompe framework across various domains.

On XX.YY.ZZ we collected WHERE all the references that cited the seminal work by Bandt and Pompe.
On that date, they were UUUU.
We marked them into 

\subsection{Biomedical Signal Processing}
In biomedical signal processing, it has been used to analyze EEG, ECG, and fMRI data, detecting anomalies such as epileptic seizures or sleep stage transitions. 
\begin{itemize}
	\item \textbf{EEG Analysis:} A study by Keller et al.~\cite{Keller2014} demonstrated the application of ordinal pattern based entropy measures, such as empirical permutation entropy (ePE), empirical conditional entropy (eCE), and robust empirical permutation entropy (rePE) to effectively analyze and classify EEG time series data, demonstrating their utility in detecting brain state transitions, segmenting non-stationary signals, and identifying change-points without relying on prior expert knowledge.
	
	\item \textbf{ECG Analysis:} Mansourian et al.~\cite{Mansourian2024} applied adaptive improved permutation entropy to extract fetal QRS complexes from single-channel abdominal ECG, enhancing the accuracy of fetal heart rate monitoring.
\end{itemize}

\subsection{Geophysics and Hydrology}
In the fields of geophysics and hydrology, PE has been applied to detect climatic variability and hydrological patterns.
\begin{itemize}
	\item \textbf{Climate Variability:}
	
	\item \textbf{Hydrological Patterns:}
\end{itemize}

\subsection{Econophysics, Optical Systems, and Engineering}
Permutation entropy has found applications in econophysics for market behavior analysis, in optical systems for detecting chaos, and in engineering for fault detection and diagnostics.
\begin{itemize}
	\item \textbf{Econophysics:}
	
	\item \textbf{Optical Systems:}
	
	\item \textbf{Engineering:}
\end{itemize}

\section{Methodological Extensions}
Recent developments have extended the methodology through multiscale approaches, cross-entropy comparisons for multivariate signals, and weighted ordinal patterns.

Furthermore, the use of alternative entropy measures such as Tsallis and Renyi entropy has been explored to better capture non-extensive and multifractal behavior in complex systems.

\textcolor{red}{Statistical properties!}

\section{Challenges and Future Directions}
Despite its success, several challenges remain in the application and development of the Bandt-Pompe approach. One major issue is the choice of embedding parameters (dimension and delay), which significantly affect the pattern distribution. Additionally, estimating entropy and complexity reliably in short time series remains difficult, prompting the need for improved statistical inference methods such as bootstrapping and confidence interval estimation.

Amigó et al.~\cite{amigo2023ordinal} emphasize the need for more robust inferential frameworks, better handling of multivariate and high-dimensional data, and integrating ordinal methods with machine learning for automated pattern recognition. As ordinal symbolic analysis continues to evolve, it holds promise for deeper insights into both theoretical dynamics and real-world systems.

As a final conclusion related to this literature review, the Bandt-Pompe method has become a foundational tool in time series analysis, offering a robust and intuitive approach to understanding complex dynamics. Through the use of ordinal patterns and entropy-based descriptors, researchers can extract meaningful information from noisy, nonlinear, and non-stationary data. While challenges remain, ongoing theoretical advances and applications across disciplines ensure the continued relevance and growth of this methodology.





